{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5889cc",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ea6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bestreads.text as text\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/goodreads_books.csv')\n",
    "data_test = data.sample(frac = 0.2, random_state = 111)\n",
    "data_train = data.drop(data_test.index)\n",
    "\n",
    "data_val = data_train.sample(frac=0.2, random_state=112)\n",
    "data_train = data_train.drop(data_val.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b66253",
   "metadata": {},
   "source": [
    "## Train-Test Set Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0212a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './data/processed/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "data_train.to_csv(save_dir + 'goodreads_books_train.csv', index = False)\n",
    "data_val.to_csv(save_dir + 'goodreads_books_val.csv', index=False)\n",
    "data_test.to_csv(save_dir + 'goodreads_books_test.csv', index = False)\n",
    "data_train.reset_index(inplace=True)\n",
    "data_val.reset_index(inplace=True)\n",
    "data_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe8710",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5cc918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_english_description_train = text.is_english(data_train['description'])\n",
    "english_descriptions_train = data_train.description[is_english_description_train]\n",
    "cleaned_descriptions_train = text.clean_text(english_descriptions_train)\n",
    "is_english_description_train = is_english_description_train.rename('is_english_description',)\n",
    "cleaned_descriptions_train = cleaned_descriptions_train.rename('cleaned_descriptions')\n",
    "\n",
    "is_english_description_val = text.is_english(data_val['description'])\n",
    "english_descriptions_val = data_val.description[is_english_description_val]\n",
    "cleaned_descriptions_val = text.clean_text(english_descriptions_val)\n",
    "is_english_description_val = is_english_description_val.rename('is_english_description',)\n",
    "cleaned_descriptions_val = cleaned_descriptions_val.rename('cleaned_descriptions')\n",
    "\n",
    "is_english_description_test = text.is_english(data_test['description'])\n",
    "english_descriptions_test = data_test.description[is_english_description_test]\n",
    "cleaned_descriptions_test = text.clean_text(english_descriptions_test)\n",
    "is_english_description_test = is_english_description_test.rename('is_english_description')\n",
    "cleaned_descriptions_test = cleaned_descriptions_test.rename('cleaned_descriptions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12809e8",
   "metadata": {},
   "source": [
    "## Grouping Descriptions by Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680680e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/Documents/bestreads/bestreads/text/text.py:144: RuntimeWarning: NaN values detected in genre_and_votes; these will beskipped\n",
      "  + 'skipped', category=RuntimeWarning)\n",
      "100%|██████████████████████████████████| 28153/28153 [00:01<00:00, 19167.41it/s]\n",
      "100%|████████████████████████████████████| 7003/7003 [00:00<00:00, 15899.66it/s]\n",
      "100%|████████████████████████████████████| 8776/8776 [00:00<00:00, 16042.33it/s]\n"
     ]
    }
   ],
   "source": [
    "genre_and_votes_train = text.get_genres(data_train.genre_and_votes[is_english_description_train])\n",
    "genre_and_votes_val = text.get_genres(data_val.genre_and_votes[is_english_description_val], n=20)\n",
    "genre_and_votes_test = text.get_genres(data_test.genre_and_votes[is_english_description_test], n=20)\n",
    "combined = text.combine_genres(genre_and_votes_train.genre_1, cleaned_descriptions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaa2ec3",
   "metadata": {},
   "source": [
    "## Calculating TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da387d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 52/52 [00:10<00:00,  4.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Historical</th>\n",
       "      <th>War</th>\n",
       "      <th>Young Adult</th>\n",
       "      <th>Science Fiction Fantasy</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Spirituality</th>\n",
       "      <th>Science Fiction</th>\n",
       "      <th>Science</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Magical Realism</th>\n",
       "      <th>...</th>\n",
       "      <th>Womens</th>\n",
       "      <th>Novels</th>\n",
       "      <th>The United States Of America</th>\n",
       "      <th>Race</th>\n",
       "      <th>Childrens</th>\n",
       "      <th>Sociology</th>\n",
       "      <th>Humor</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Womens Fiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ivi</th>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>birth</th>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Historical       War  Young Adult  Science Fiction Fantasy   Mystery  \\\n",
       "ivi      0.000351  0.000014     0.000163                 0.000104  0.000093   \n",
       "row      0.000023  0.000010     0.000047                 0.000000  0.000026   \n",
       "birth    0.000128  0.000051     0.000036                 0.000081  0.000036   \n",
       "blue     0.000036  0.000030     0.000083                 0.000073  0.000063   \n",
       "star     0.000047  0.000035     0.000073                 0.000056  0.000068   \n",
       "\n",
       "       Spirituality  Science Fiction   Science  Thriller  Magical Realism  \\\n",
       "ivi        0.000000         0.000032  0.000000  0.000057         0.000000   \n",
       "row        0.000000         0.000037  0.000015  0.000106         0.000000   \n",
       "birth      0.000052         0.000059  0.000084  0.000046         0.000034   \n",
       "blue       0.000021         0.000036  0.000052  0.000049         0.000103   \n",
       "star       0.000002         0.000120  0.000034  0.000053         0.000029   \n",
       "\n",
       "       ...    Womens    Novels  The United States Of America      Race  \\\n",
       "ivi    ...  0.000000  0.000000                      0.000000  0.000000   \n",
       "row    ...  0.000000  0.000000                      0.000000  0.000225   \n",
       "birth  ...  0.000132  0.000036                      0.000000  0.000000   \n",
       "blue   ...  0.000000  0.000056                      0.000161  0.000242   \n",
       "star   ...  0.000047  0.000074                      0.000206  0.000015   \n",
       "\n",
       "       Childrens  Sociology     Humor   Writing  Religion  Womens Fiction  \n",
       "ivi     0.000000   0.000000  0.000000  0.000000  0.000000        0.000063  \n",
       "row     0.000000   0.000046  0.000000  0.000000  0.000000        0.000018  \n",
       "birth   0.000000   0.000049  0.000029  0.000046  0.000088        0.000048  \n",
       "blue    0.000566   0.000042  0.000101  0.000039  0.000022        0.000089  \n",
       "star    0.000032   0.000015  0.000074  0.000047  0.000014        0.000093  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_table_train = text.tf_idf(combined)\n",
    "\n",
    "# Here, we save the index because each index is a word\n",
    "tf_idf_table_train.to_csv(save_dir + 'tf_idf_table_train.csv', index_label='word')\n",
    "tf_idf_table_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41a0dff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the training data\n",
    "processed_data_train = (is_english_description_train.to_frame()\n",
    "                        .merge(cleaned_descriptions_train,\n",
    "                               left_index=True, right_index=True,\n",
    "                               validate='1:1')\n",
    "                        .merge(genre_and_votes_train,\n",
    "                               left_index=True, right_index=True,\n",
    "                               validate='1:1'))\n",
    "\n",
    "# Here, we save the index because some rows are now missing due to\n",
    "# english language selection\n",
    "processed_data_train.to_csv(save_dir + 'goodreads_books_train_processed.csv', \n",
    "                            index_label='index')\n",
    "\n",
    "# Save the validation\n",
    "processed_data_val = (is_english_description_val.to_frame()\n",
    "                        .merge(cleaned_descriptions_val,\n",
    "                               left_index=True, right_index=True,\n",
    "                               validate='1:1')\n",
    "                        .merge(genre_and_votes_val,\n",
    "                               left_index=True, right_index=True,\n",
    "                               validate='1:1'))\n",
    "\n",
    "# Here, we save the index because some rows are now missing due to\n",
    "# english language selection\n",
    "processed_data_val.to_csv(save_dir + 'goodreads_books_val_processed.csv', \n",
    "                          index_label='index')\n",
    "\n",
    "# Save the test data\n",
    "processed_data_test = (is_english_description_test.to_frame()\n",
    "                        .merge(cleaned_descriptions_test,\n",
    "                               left_index=True, right_index=True,\n",
    "                               validate='1:1')\n",
    "                        .merge(genre_and_votes_test,\n",
    "                               left_index=True, right_index=True,\n",
    "                               validate='1:1'))\n",
    "\n",
    "# Here, we save the index because some rows are now missing due to\n",
    "# english language selection\n",
    "processed_data_test.to_csv(save_dir + 'goodreads_books_test_processed.csv', \n",
    "                           index_label='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
